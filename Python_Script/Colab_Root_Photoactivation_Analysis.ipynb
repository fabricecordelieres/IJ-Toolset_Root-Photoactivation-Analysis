{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+121g0JjOIV2tE8L2x/q5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabricecordelieres/IJ-Toolset_Root-Photoactivation-Analysis/blob/main/Python_Script/Colab_Root_Photoactivation_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Data Pulling Notebook**\n",
        "\n",
        "---\n",
        "## **Data organization**\n",
        "This notebook takes as an input a single zip file containing one subfolder per condition, each containing individual csv and jpg files per cell. Each csv file contains integrated fluorence and area for the following regions of insterest:\n",
        "* \"Activated Cell\": Dronpa activated cell.\n",
        "* A variable number of \"Bording cells\": Border Cell X, on the root tip side, and Border Cell X', on the opposite side.\n",
        "* \"Background\": the detected cells that is the furthest away from the activated cell.\n",
        "\n",
        "**Input zip file structure:**\n",
        "  - *Sub-folder 1: condition 1*\n",
        "    - Raw data, acquisition 1, as a csv file\n",
        "    - Segmentation control, acquisition 1, as a jpg file \n",
        "    - Raw data, acquisition 2, as a csv file\n",
        "    - Segmentation control, acquisition 2, as a jpg file \n",
        "    - ...\n",
        "    - Raw data, acquisition m, as a csv file\n",
        "    - Segmentation control, acquisition m, as a jpg file \n",
        "  - *Sub-folder 2: condition 2*\n",
        "    - Raw data, acquisition 1, as a csv file\n",
        "    - Segmentation control, acquisition 1, as a jpg file \n",
        "    - Raw data, acquisition 2, as a csv file\n",
        "    - Segmentation control, acquisition 2, as a jpg file \n",
        "    - ...\n",
        "    - Raw data, acquisition m, as a csv file\n",
        "    - Segmentation control, acquisition m, as a jpg file \n",
        "  - *...*\n",
        "  - *Sub-folder n: condition n*\n",
        "    - Raw data, acquisition 1, as a csv file\n",
        "    - Segmentation control, acquisition 1, as a jpg file \n",
        "    - Raw data, acquisition 2, as a csv file\n",
        "    - Segmentation control, acquisition 2, as a jpg file \n",
        "    - ...\n",
        "    - Raw data, acquisition m, as a csv file\n",
        "    - Segmentation control, acquisition m, as a jpg file \n",
        "\n",
        "\n",
        "This notebook will organise the data into one excel workbook per condition, each acquisition being copied to a single spreadsheet. It will also create a summary sheet containing mean, SD and n for each acquisition and each type of cell. For both individual acquisitions and summarized data, a chart will be generated\n",
        "\n",
        "---\n",
        "## **Data correction and normalization**\n",
        "Data will be first corrected for background as follows:\n",
        "\n",
        "<p align=center> $Integrated\\ density(Cell_{Background\\ corrected})=Integrated\\ density(Cell_{Raw})-\\frac{Integrated\\ density(Cell_{Background})}{Area(Cell_{Background})}*Area(Cell_{Raw})$\n",
        "\n",
        "Normalisation is performed from background corrected data, assuming the total fluorescence between the activated cell and bording cells is only exchanged. It is assumed the systems acts as a closed container: no material leaves or enters the system made of the activated cells and the bording cells. The total fluorescence over those cells of interest is therefore normalised to 1:\n",
        "\n",
        "<p align=center> $Normalised\\ fluorescence(Cell)=\\frac{Integrated\\ density(Cell_{Background\\ corrected})}{\\sum_{i} Integrated\\ density(Cell_{i, Background\\ corrected})}$\n",
        "\n",
        "---\n",
        "## **How to run this script**\n",
        "\n",
        "1.   Have all you data ready: the toolset should have agenerated a **\"_dataToUpload.zip\"** file in the output folder: locate it and get ready to select it when asked.\n",
        "2.   Run each step: press the play button, on the left side of the relevent cells\n",
        "  1. Step 1 is non interactive: point at the \\[   \\] mark. It will change to a play button. Press play and wait for a green tick mark to appear on the left.\n",
        "  2. Step 2 is interactive nad should be performed in two steps:\n",
        "    1. Step 2.1: point at the \\[   \\] mark. It will change to a play button. Press play: a **\"Select file\"** button should appear below the cell. use it to navigate your drive and locate the zip file. The selected file will be uploaded to the swap space of the Google Colab environment, will be unzip and data compilation will occur. The resulting files will be zipped and directlt downloaded to your computer.\n",
        "    2. Step 2.2: point at the \\[   \\] mark. It will change to a play button. Press play: this step will remove the zip file that has been generated. **DO NOT PRESS PLAY BEFORE THE DOWNLOAD HAS OCCURED !**\n",
        "\n",
        "**_If you are planning on compiling more than one zip files, you don't have to re-run step 1: simply run steps 2.1 and 2.2 for each individual file._**"
      ],
      "metadata": {
        "id": "NP4b19Krfbud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Prepare the environment for execution"
      ],
      "metadata": {
        "id": "TPfjnox4MHQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.1: Install librairies_**"
      ],
      "metadata": {
        "id": "17tdFe4YN6ui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Noshja_QaKnA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "! pip install XlsxWriter\n",
        "\n",
        "#from google.colab import drive\n",
        "#import math\n",
        "#import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2: Declare some helping functions_**\n",
        "_Defines procedures to load the data csv files and create xlsx formatted files_"
      ],
      "metadata": {
        "id": "cQlNUruwOGi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.1: Defines how to process csv files_**"
      ],
      "metadata": {
        "id": "VKeRBU-cPoAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#-----------------LOAD AND MANIPULATE CSV FILES-----------------\n",
        "import pandas as pd\n",
        "\n",
        "class read_csv():\n",
        "  \"\"\"Reads a single csv file, from an input path, \n",
        "  and performs the required data formatting\n",
        "\n",
        "  Keyword argument:\n",
        "    path -- path to the data file\"\"\"\n",
        "\n",
        "  #Class attibute\n",
        "  data=pd.DataFrame()\n",
        "\n",
        "  def __init__(self, path=''):\n",
        "    self.data=pd.read_csv(path).iloc[0::2].reset_index(drop=True) # lines 1, 3, 4...\n",
        "    # self.data=pd.read_csv(path).iloc[1::2] lines 2, 4, 6...\n",
        "\n",
        "  def get_data(self):\n",
        "    \"\"\"Returns the relevent data, as a DataFrame\"\"\"\n",
        "    return self.data"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7YKtCPJrPeWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.2: Defines how to read params.txt file_**"
      ],
      "metadata": {
        "id": "zTE3AmGPUMMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#-----------------LOAD AND MANIPULATE PARAMS.TXT FILES-----------------\n",
        "class read_param():\n",
        "  \"\"\"Reads the parameters file, from an input path, \n",
        "\n",
        "  Keyword argument:\n",
        "    path -- path to the parameters file\"\"\"\n",
        "\n",
        "  #Stores parameters as key values\n",
        "  params={}\n",
        "  \n",
        "  #List of subfolders\n",
        "  paths=''\n",
        "\n",
        "  #Number of bording layers\n",
        "  n_bording_layers=0\n",
        "\n",
        "  def __init__(self, path=''):\n",
        "    file = open(path, 'r')\n",
        "    lines = file.readlines()\n",
        "\n",
        "    self.params = dict(line.rstrip().split('=',1) for line in lines)\n",
        "\n",
        "    self.paths=self.params['paths'].split(',')\n",
        "    self.n_bording_layers=int(self.params['nBordingCells'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m6fkCDcHULNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.3: Defines how to compile csv files to a xlsx file_**"
      ],
      "metadata": {
        "id": "5sJvjmroP1jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#-----------------CREATE OUTPUT XLS FILE-----------------\n",
        "import xlsxwriter\n",
        "from xlsxwriter.utility import xl_rowcol_to_cell\n",
        "import os\n",
        "import re\n",
        "\n",
        "class create_XLSX():\n",
        "  \"\"\"Creates a XLSX file, in an output folder, \n",
        "  adds one sheet per input file,\n",
        "  adds the formula and charts,\n",
        "  adds a compiled data and a summary sheet\n",
        "\n",
        "  Keyword argument:\n",
        "    path -- path to the data file\"\"\"\n",
        "\n",
        "  \n",
        "  #Class attibute\n",
        "  in_path=''\n",
        "  dataset=''\n",
        "  files_list=''\n",
        "  out_path=''\n",
        "  workbook_path=''\n",
        "  workbook = ''\n",
        "  title_format=''\n",
        "  headers_format=''\n",
        "  cells_timesteps_format=''\n",
        "  cells_format=''\n",
        "\n",
        "  #Hard-coded parameters\n",
        "  timestamps=''\n",
        "  rois_labels=''\n",
        "  data_labels=''\n",
        "\n",
        "  n_bording_layers=0 #Number of bording layers\n",
        "\n",
        "  summary='' #The summary worksheet\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def __init__(self, in_path='', out_path='', n_bording_layers=0):\n",
        "    #Initializes headers\n",
        "    self.timestamps=['Before activation', 'Activation', '2 sec activation', 15, 30, 45, 60, 75, 90, 105, 120]\n",
        "    self.rois_labels=['Background', 'Activated Cell']\n",
        "    self.data_labels=['Raw data', 'Background subtracted', 'Normalized to 1', 'Normalized to 100%']\n",
        "\n",
        "\n",
        "    #Prepares path and names\n",
        "    self.in_path=in_path\n",
        "    tmp=in_path.split('/')\n",
        "    self.dataset=tmp[len(tmp)-2] # the path is supposed to end with /: last element of the table is therefore empty\n",
        "    self.out_path=out_path\n",
        "    self.n_bording_layers=n_bording_layers\n",
        "\n",
        "    #Prepares the labels\n",
        "    for i in range(1, n_bording_layers+1):\n",
        "      self.rois_labels.append('Border Cell '+str(i))\n",
        "      self.rois_labels.append('Border Cell '+str(i)+\"'\")\n",
        "\n",
        "    #Checks for previous XLSX output and removes it if it exists\n",
        "    self.workbook_path=self.out_path+self.dataset+'.xlsx'\n",
        "    if os.path.exists(self.workbook_path):\n",
        "      os.remove(self.workbook_path)\n",
        "\n",
        "    #Get the list of all files to analyze\n",
        "    self.files_list=[f.replace('.csv', '') for f in os.listdir(in_path) if (os.path.isfile(os.path.join(in_path, f)) and f.endswith('.csv'))]\n",
        "    self.files_list.sort()\n",
        "\n",
        "    #Creates the XLSX output\n",
        "    self.workbook = xlsxwriter.Workbook(self.workbook_path)\n",
        "\n",
        "    # Create a format to use for title\n",
        "    self.title_format = self.workbook.add_format({\n",
        "      'bold': 1,\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "  \n",
        "    # Create a format to use for headers\n",
        "    self.headers_format = self.workbook.add_format({\n",
        "      'bold': 1,\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "    \n",
        "    # Create a format to use for cells\n",
        "    self.cells_timesteps_format = self.workbook.add_format({\n",
        "      'bold': 1,\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "    \n",
        "    # Create a format to use for cells\n",
        "    self.cells_format = self.workbook.add_format({\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def create_all_worksheets(self):\n",
        "    \"\"\"Creates and feeds all the spreadsheets based on the content of the input folder\"\"\"\n",
        "\n",
        "    print('******* Processing dataset '+self.dataset+' *******')\n",
        "    self.summary = self.workbook.add_worksheet('Summary')\n",
        "    print('Added Summary worksheet')\n",
        "    for f in self.files_list:\n",
        "      self.create_and_feed_single_worksheet(f)\n",
        "    self.feed_summary_worksheet()\n",
        "    self.workbook.close()\n",
        "\n",
        "    print('******* Done *******')\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def create_and_feed_single_worksheet(self, name):\n",
        "    \"\"\"Creates a single spreasheet from a single csv file\n",
        "\n",
        "    Keyword argument:\n",
        "    name -- name of the input csv file\"\"\"\n",
        "\n",
        "    worksheet = self.workbook.add_worksheet(name)\n",
        "    print('Added', name, 'worksheet')\n",
        "\n",
        "    #Reads data\n",
        "    input_csv=read_csv(self.in_path+name+\".csv\")\n",
        "    data=input_csv.get_data()\n",
        "\n",
        "    # Define offsets to put data and hard coded data\n",
        "    offset_row=4 #Depends on the number of lines for the headers\n",
        "    block_size=2*(2+self.n_bording_layers*2) #Headers' block size= (Bkgd+Activated+ 2*cells/layer)*2columns\n",
        "    \n",
        "    # --------Handles the raw data--------\n",
        "    #Adds general headers\n",
        "    worksheet.merge_range(0, 0, 0, block_size*len(self.data_labels), name, self.title_format)\n",
        "    worksheet.merge_range('A2:A4', 'Time', self.headers_format)\n",
        "\n",
        "    #Adds data header\n",
        "    index_data=0\n",
        "\n",
        "    for label in self.data_labels:\n",
        "      worksheet.merge_range(1, block_size*index_data+1, 1, block_size*index_data+block_size, label, self.headers_format)\n",
        "      \n",
        "      index_roi=0\n",
        "      for roi in self.rois_labels:\n",
        "        #Adds cell/data headers\n",
        "        worksheet.merge_range(2, 2*index_roi+1+block_size*index_data, 2, 2*index_roi+2+block_size*index_data, roi, self.headers_format)\n",
        "        worksheet.write(3, 2*index_roi+1+block_size*index_data, 'Area', self.headers_format)\n",
        "        worksheet.write(3, 2*index_roi+2+block_size*index_data, data['Area('+self.rois_labels[index_roi]+')'][0], self.headers_format)\n",
        "        index_roi=index_roi+1\n",
        "\n",
        "      index_data=index_data+1\n",
        "\n",
        "    \n",
        "    #Adds timestamp\n",
        "    index=0\n",
        "    for row in self.timestamps:\n",
        "      worksheet.write(index+offset_row, 0, row, self.cells_timesteps_format)\n",
        "      index=index+1\n",
        "\n",
        "    #Adds raw data\n",
        "    index_roi=0\n",
        "    nCol_per_dataType=2*len(self.rois_labels)\n",
        "    area_background='$C$4'  \n",
        "    for roi in self.rois_labels:\n",
        "      #Locate the area cells\n",
        "      area_curr_cell='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3, 2*index_roi+2))[0:2])\n",
        "\n",
        "      for row in range(len(data['RawIntDen('+self.rois_labels[index_roi]+')'])):\n",
        "        \n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1, row+offset_row, 2*index_roi+2, data['RawIntDen('+self.rois_labels[index_roi]+')'][row], self.cells_format)\n",
        "        \n",
        "        #Before activation subtracted\n",
        "        raw_background=xl_rowcol_to_cell(row+offset_row, 1)\n",
        "        raw_current_cell=xl_rowcol_to_cell(row+offset_row, 2*index_roi+1)\n",
        "\n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1+nCol_per_dataType, row+offset_row, 2*index_roi+2+nCol_per_dataType, '='+raw_current_cell+'-'+raw_background+'*'+area_curr_cell+'/'+area_background, self.cells_format)\n",
        "        \n",
        "        #Adds formulas for computations\n",
        "        #Normalized to 1 and %\n",
        "        sum_cells='+'.join([xl_rowcol_to_cell(row+offset_row, 2*cell+1+nCol_per_dataType) for cell in range(1, 2*self.n_bording_layers+2)])\n",
        "        \n",
        "        curr_cell=xl_rowcol_to_cell(row+offset_row, 2*index_roi+1+nCol_per_dataType)\n",
        "        formula='='+curr_cell+'/('+sum_cells+')'\n",
        "\n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1+2*nCol_per_dataType, row+offset_row, 2*index_roi+2+2*nCol_per_dataType, formula, self.cells_format)\n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1+3*nCol_per_dataType, row+offset_row, 2*index_roi+2+3*nCol_per_dataType, formula.replace('=', '=100*'), self.cells_format)\n",
        "      index_roi=index_roi+1\n",
        "\n",
        "    #Formats the data\n",
        "    #Column width\n",
        "    worksheet.set_column(0, 0, 14.5)\n",
        "    worksheet.set_column(1, 1, 9)\n",
        "    worksheet.set_column(1, 2, 9)\n",
        "\n",
        "    #Adds graphs\n",
        "    #graph=self.workbook.add_chart({'type': 'scatter', 'subtype': 'smooth_with_markers'})\n",
        "    graph=self.workbook.add_chart({'type': 'line'})\n",
        "\n",
        "\n",
        "    # Configure the data series.\n",
        "    for roi in range(len(self.rois_labels)):\n",
        "      #Defines cells locations\n",
        "      n_lines=len(data['RawIntDen('+self.rois_labels[roi]+')'])-1+offset_row\n",
        "      col_data=2*roi+1+3*nCol_per_dataType\n",
        "\n",
        "      name_cell='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(2, col_data))[0:2])\n",
        "      categories_cell_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(offset_row+1, 0))[0:2])\n",
        "      categories_cell_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(n_lines, 0))[0:2])\n",
        "      values_cells_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(offset_row+1, col_data))[0:2])\n",
        "      values_cells_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(n_lines, col_data))[0:2])\n",
        "      \n",
        "      #Adds series to the graph\n",
        "      graph.add_series({\n",
        "          'name':       '='+name+'!'+name_cell,\n",
        "          'categories': '='+name+'!'+categories_cell_start+':'+categories_cell_end,\n",
        "          'values':     '='+name+'!'+values_cells_start+':'+values_cells_end,\n",
        "          #'data_labels': {'series_name': True},\n",
        "      })\n",
        "\n",
        "    #Graph formatting\n",
        "    graph.set_title({'name': name})\n",
        "    graph.set_x_axis({\n",
        "        'name' : 'Timepoint',\n",
        "        'text_axis': True,\n",
        "        'num_font':  {'rotation': -45},\n",
        "    })\n",
        "    graph.set_y_axis({\n",
        "        'name' : 'Normalized fluorescence (%)',\n",
        "    })\n",
        "    graph.set_size({\n",
        "        'width': 1024,\n",
        "        'height': 512,\n",
        "    })\n",
        "\n",
        "    #Inserts the graph\n",
        "    insert_graph_cell=xl_rowcol_to_cell(n_lines+2, 0)\n",
        "    worksheet.insert_chart(insert_graph_cell, graph)\n",
        "\n",
        "    #Inserts image\n",
        "    insert_img_cell=xl_rowcol_to_cell(n_lines+2, 16)\n",
        "    worksheet.insert_image(insert_img_cell, self.in_path+name+\".jpg\")\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def feed_summary_worksheet(self):\n",
        "    \"\"\"Feeds a summary spreasheet\"\"\"\n",
        "\n",
        "    n_rois=len(self.rois_labels) \n",
        "    n_files=len(self.files_list)\n",
        "    n_timepoints=len(self.timestamps)\n",
        "    n_value_types=len(self.data_labels)\n",
        "    n_col_per_data=2\n",
        "    offset_row=1;\n",
        "\n",
        "    #Adds headers\n",
        "    self.summary.merge_range(0, 0, 0, (n_files+3)*(n_rois-1), 'Data summary for '+self.dataset, self.title_format)\n",
        "    self.summary.merge_range('A2:A3', 'Time', self.headers_format)\n",
        "\n",
        "    index=1\n",
        "    for roi in range(1, n_rois): #Starts after background ROI\n",
        "      self.summary.merge_range(offset_row, (roi-1)*(n_files+3)+1, offset_row, roi*(n_files+3), self.rois_labels[roi], self.headers_format)\n",
        "      for dataset in self.files_list:\n",
        "        self.summary.write(offset_row+1, index, dataset, self.headers_format)\n",
        "        index=index+1\n",
        "      self.summary.write(offset_row+1, index, 'Mean', self.headers_format)\n",
        "      self.summary.write(offset_row+1, index+1, 'SD', self.headers_format)\n",
        "      self.summary.write(offset_row+1, index+2, 'n', self.headers_format)\n",
        "      index=index+3\n",
        "\n",
        "    #Adds timestamp\n",
        "    offset_row=offset_row+2\n",
        "\n",
        "    index=0\n",
        "    for row in self.timestamps:\n",
        "      self.summary.write(index+offset_row, 0, row, self.cells_timesteps_format)\n",
        "      index=index+1\n",
        "    \n",
        "    #Adds references to data and computes stats\n",
        "    for timepoint in range(0, n_timepoints):\n",
        "      index=1\n",
        "      for roi in range(1, n_rois): #Starts after background ROI\n",
        "        cell_to_ref=xl_rowcol_to_cell(offset_row+timepoint+1, 1+(n_col_per_data*n_rois)*(n_value_types-1)+2*roi)\n",
        "        data_cells=[]\n",
        "        for dataset in self.files_list:\n",
        "          self.summary.write(offset_row+timepoint, index, '='+dataset+'!'+cell_to_ref, self.cells_format)\n",
        "          data_cells.append(xl_rowcol_to_cell(offset_row+timepoint, index))\n",
        "          index=index+1\n",
        "        self.summary.write(offset_row+timepoint, index, '=AVERAGE('+data_cells[0]+':'+data_cells[len(data_cells)-1]+')', self.headers_format)\n",
        "        self.summary.write(offset_row+timepoint, index+1, '=STDEV('+data_cells[0]+':'+data_cells[len(data_cells)-1]+')', self.headers_format)\n",
        "        self.summary.write(offset_row+timepoint, index+2, '=COUNT('+data_cells[0]+':'+data_cells[len(data_cells)-1]+')', self.headers_format)\n",
        "        index=index+3\n",
        "\n",
        "    #Formats the data\n",
        "    #Column width\n",
        "    self.summary.set_column(0, 0, 14.5)\n",
        "    self.summary.set_column(1, 1, 9)\n",
        "    self.summary.set_column(1, 2, 9)\n",
        "\n",
        "    #Adds graphs\n",
        "    graph=self.workbook.add_chart({'type': 'line'})\n",
        "\n",
        "    n_lines=len(self.timestamps)-1\n",
        "    categories_cell_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+1, 0))[0:2])\n",
        "    categories_cell_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+n_lines, 0))[0:2])\n",
        "      \n",
        "    for roi in range(1, n_rois): #Starts after background ROI\n",
        "      #Defines cells locations\n",
        "      name_cell='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(1, 1+(n_files+3)*(roi-1)))[0:2])\n",
        "\n",
        "      values_cells_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+1, 1+(n_files+3)*(roi-1)+n_files))[0:2])\n",
        "      values_cells_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+n_lines, 1+(n_files+3)*(roi-1)+n_files))[0:2])\n",
        "\n",
        "      sd_cells_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+1, 1+(n_files+3)*(roi-1)+n_files+1))[0:2])\n",
        "      sd_cells_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+n_lines, 1+(n_files+3)*(roi-1)+n_files+1))[0:2])\n",
        "\n",
        "      #Adds series to the graph\n",
        "      graph.add_series({\n",
        "          'name':       '=Summary!'+name_cell,\n",
        "          'categories': '=Summary!'+categories_cell_start+':'+categories_cell_end,\n",
        "          'values':     '=Summary!'+values_cells_start+':'+values_cells_end,\n",
        "          'y_error_bars': {\n",
        "            'type':         'custom',\n",
        "            'plus_values':  '=Summary!'+sd_cells_start+':'+sd_cells_end,\n",
        "            'minus_values': '=Summary!'+sd_cells_start+':'+sd_cells_end,\n",
        "          },\n",
        "          #'data_labels': {'series_name': True},\n",
        "      })\n",
        "\n",
        "    #Graph formatting\n",
        "    graph.set_title({'name': 'Data summary for '+self.dataset})\n",
        "    graph.set_x_axis({\n",
        "        'name' : 'Timepoint',\n",
        "        'text_axis': True,\n",
        "        'num_font':  {'rotation': -45},\n",
        "    })\n",
        "    graph.set_y_axis({\n",
        "        'name' : 'Normalized fluorescence (%)',\n",
        "    })\n",
        "    graph.set_size({\n",
        "        'width': 1024,\n",
        "        'height': 512,\n",
        "    })\n",
        "\n",
        "    #Inserts the graph\n",
        "    insert_graph_cell=xl_rowcol_to_cell(n_lines+5, 0)\n",
        "    self.summary.insert_chart(insert_graph_cell, graph)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ssPlEzldNfMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.4: Defines how to upload the data, launch analysis and download the results, while keeping the swapping space clean_**"
      ],
      "metadata": {
        "id": "zNROf2gXQSjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "import shutil\n",
        "import os\n",
        "#-----------------UPLOAD DATA, PERFORM ANALYSIS AND DOWNLOAD THE RESULTS-----------------\n",
        "class compile_data():\n",
        "  \"\"\"\n",
        "  1-Uploads a zip file\n",
        "  2-Unzips it\n",
        "  3-Performs the analysis on all folders\n",
        "  4-Zips the results\n",
        "  5-Downloads the output zip file\n",
        "  \"\"\"\n",
        "\n",
        "  #Class attibute\n",
        "  uploaded=''\n",
        "  in_dir=''\n",
        "  in_file=''\n",
        "  out_file=''\n",
        "\n",
        "  def __init__(self):\n",
        "    '''Uploads the input zip file and keeps track of it as a class attribute'''\n",
        "    #File chooser\n",
        "    self.uploaded = files.upload()\n",
        "\n",
        "  def generate_output(self):\n",
        "    '''Unzips the uploaded file, performs analysis, creates the output zip file and downlaods it'''\n",
        "    #Unzip file(s), analyzes/downloads/clean up\n",
        "    for filename in self.uploaded.keys():\n",
        "      #Create a folder named after the file\n",
        "      zip_extract_path='/content/'+filename.replace('.zip', '')\n",
        "      os.mkdir(zip_extract_path)\n",
        "\n",
        "      #Extract the file\n",
        "      zip_in=ZipFile(filename, 'r')\n",
        "      zip_in.extractall(zip_extract_path)\n",
        "      zip_in.close()\n",
        "\n",
        "      #Analyze\n",
        "      self.in_file='/content/'+filename\n",
        "      self.in_dir=self.in_file.replace('.zip', '/')\n",
        "      self.out_file='/content/_dataAnalysed.zip'\n",
        "      params=read_param(self.in_dir+'params.txt')\n",
        "\n",
        "      out_dir=self.in_dir+'output/'\n",
        "      if not os.path.exists(out_dir):\n",
        "        os.mkdir(out_dir)\n",
        "\n",
        "      for dataset in params.paths:\n",
        "        in_path=self.in_dir+dataset\n",
        "        curr_xls=create_XLSX(in_path, out_dir, params.n_bording_layers)\n",
        "        curr_xls.create_all_worksheets()\n",
        "\n",
        "      zip_out = ZipFile(self.out_file, \"w\")\n",
        "      xlsx_files=[f for f in os.listdir(out_dir) if (os.path.isfile(os.path.join(out_dir, f)) and f.endswith('.xlsx'))]\n",
        "      \n",
        "      for f in xlsx_files:\n",
        "        zip_out.write(os.path.join(out_dir, f), f)\n",
        "      zip_out.close()\n",
        "\n",
        "      files.download(self.out_file)\n",
        "      self.clean_up_ze_mess()\n",
        "\n",
        "  def clean_up_ze_mess(self):\n",
        "    \"\"\"Removes the input zip file and the extracted folders\"\"\"\n",
        "    if(os.path.exists('/content/__MACOSX')):\n",
        "      shutil.rmtree('/content/__MACOSX')\n",
        "    shutil.rmtree(self.in_dir)\n",
        "    os.remove(self.in_file)\n",
        "\n",
        "  def delete_output_file(self):\n",
        "    '''Deletes the output zip file: DO NOT CALL IT BEFORE DOWNLOAD HAS ENDED'''\n",
        "    os.remove(self.out_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s1iZpq8eQWxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Performs the analysis: upload data, analyze, download results\n"
      ],
      "metadata": {
        "id": "kowdervwOni-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 2.1: Upload data, analyze and download results_**\n",
        "_Processes the data_\n",
        "_Simply execute the following cell_"
      ],
      "metadata": {
        "id": "OuQpuLsqO6Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "where_the_magic_happens=compile_data()\n",
        "where_the_magic_happens.generate_output()"
      ],
      "metadata": {
        "id": "9TtqNaWkiTd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 2.2: Clean up temporary data_**\n",
        "_Cleans up the workspace: **to be executed once the results have been generated and downloaded**_"
      ],
      "metadata": {
        "id": "c-oPZYAWVIjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "where_the_magic_happens.delete_output_file()"
      ],
      "metadata": {
        "id": "Cmem3Ve_ibW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}