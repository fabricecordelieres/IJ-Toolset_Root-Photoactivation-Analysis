{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmo086CRIeCOyFLhvGQXIG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabricecordelieres/IJ-Toolset_Root-Photoactivation-Analysis/blob/main/Python_Script/Colab_Root_Photoactivation_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Data Pulling Notebook\n",
        "---\n",
        "*This notebook takes as an input a folder containing one subfolder per condition, each containing individual csv files. Each csv file contains fluorescence information about cell 0 (Drompa activated cell) and the two receiving/bording cells (cell -1 and cell 1). This notebook will organise the data into one excel workbook per condition, each acquisition being copied to a single spreadsheet. Data will be normalised to 100% for cell 0 immediately after activation. A summary spreadsheet will be generated containing mean, SD and n for each condition. For both individual acqusitions and summarized data, a chart will be generated*\n",
        "\n",
        "\n",
        "\n",
        "## Data organization\n",
        "\n",
        "**Input folder:**\n",
        "\n",
        "---\n",
        "  - *Sub-folder 1: condition 1*\n",
        "    - Raw data, acquisition 1, as a csv file \n",
        "    - Raw data, acquisition 2, as a csv file\n",
        "    - ...\n",
        "    - Raw data, acquisition m, as a csv file\n",
        "---\n",
        "  - *Sub-folder 2: condition 2*\n",
        "    - Raw data, acquisition 1, as a csv file \n",
        "    - Raw data, acquisition 2, as a csv file\n",
        "    - ...\n",
        "    - Raw data, acquisition m, as a csv file\n",
        "---\n",
        "  - *...*\n",
        "---\n",
        "  - *Sub-folder n: condition n*\n",
        "    - Raw data, acquisition 1, as a csv file \n",
        "    - Raw data, acquisition 2, as a csv file\n",
        "    - ...\n",
        "    - Raw data, acquisition m, as a csv file\n",
        "---\n",
        "\n",
        "\n",
        "## **How to run this script**\n",
        "\n",
        "1.   Have all you data ready on the Google Drive: one folder with one sub-folder per condition, all the raw data files in each sub-folder\n",
        "2.   Run each steps: press the play button, on the left side of the relevent cells\n",
        "  1. Step 1 only is interactive: it will require that acces is given by the Google Drive to the script. Simply follow the procedure explained at Step 1.1\n",
        "  2. Step 1.2 is also interactive: give the path to the folder containing all files, then run the cell.\n",
        "3. At the end of the script, for each file, a file_with-NN is created in the same folder as the source data.\n"
      ],
      "metadata": {
        "id": "NP4b19Krfbud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Prepare the environment for execution"
      ],
      "metadata": {
        "id": "TPfjnox4MHQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.1: Install librairies_**"
      ],
      "metadata": {
        "id": "17tdFe4YN6ui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Noshja_QaKnA",
        "outputId": "485a15b6-a8eb-4c02-a49a-11e6c24f7e24",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting XlsxWriter\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: XlsxWriter\n",
            "Successfully installed XlsxWriter-3.0.3\n"
          ]
        }
      ],
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "! pip install XlsxWriter\n",
        "\n",
        "#from google.colab import drive\n",
        "#import math\n",
        "#import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2: Declare some helping functions_**\n",
        "_Defines procedures to load the data csv files and create xlsx formatted files_"
      ],
      "metadata": {
        "id": "cQlNUruwOGi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.1: Defines how to process csv files_**"
      ],
      "metadata": {
        "id": "VKeRBU-cPoAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#-----------------LOAD AND MANIPULATE CSV FILES-----------------\n",
        "import pandas as pd\n",
        "\n",
        "class read_csv():\n",
        "  \"\"\"Reads a single csv file, from an input path, \n",
        "  and performs the required data formatting\n",
        "\n",
        "  Keyword argument:\n",
        "    path -- path to the data file\"\"\"\n",
        "\n",
        "  #Class attibute\n",
        "  data=pd.DataFrame()\n",
        "\n",
        "  def __init__(self, path=''):\n",
        "    self.data=pd.read_csv(path).iloc[0::2].reset_index(drop=True) # lines 1, 3, 4...\n",
        "    # self.data=pd.read_csv(path).iloc[1::2] lines 2, 4, 6...\n",
        "\n",
        "  def get_data(self):\n",
        "    \"\"\"Returns the relevent data, as a DataFrame\"\"\"\n",
        "    return self.data"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7YKtCPJrPeWQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.2: Defines how to read params.txt file_**"
      ],
      "metadata": {
        "id": "zTE3AmGPUMMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#-----------------LOAD AND MANIPULATE PARAMS.TXT FILES-----------------\n",
        "class read_param():\n",
        "  \"\"\"Reads the parameters file, from an input path, \n",
        "\n",
        "  Keyword argument:\n",
        "    path -- path to the parameters file\"\"\"\n",
        "\n",
        "  #Stores parameters as key values\n",
        "  params={}\n",
        "  \n",
        "  #List of subfolders\n",
        "  paths=''\n",
        "\n",
        "  #Number of bording layers\n",
        "  n_bording_layers=0\n",
        "\n",
        "  def __init__(self, path=''):\n",
        "    file = open(path, 'r')\n",
        "    lines = file.readlines()\n",
        "\n",
        "    self.params = dict(line.rstrip().split('=',1) for line in lines)\n",
        "\n",
        "    self.paths=self.params['paths'].split(',')\n",
        "    self.n_bording_layers=int(self.params['nBordingCells'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m6fkCDcHULNB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.3: Defines how to compile csv files to a xlsx file_**"
      ],
      "metadata": {
        "id": "5sJvjmroP1jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "#-----------------CREATE OUTPUT XLS FILE-----------------\n",
        "import xlsxwriter\n",
        "from xlsxwriter.utility import xl_rowcol_to_cell\n",
        "import os\n",
        "import re\n",
        "\n",
        "class create_XLSX():\n",
        "  \"\"\"Creates a XLSX file, in an output folder, \n",
        "  adds one sheet per input file,\n",
        "  adds the formula and charts,\n",
        "  adds a compiled data and a summary sheet\n",
        "\n",
        "  Keyword argument:\n",
        "    path -- path to the data file\"\"\"\n",
        "\n",
        "  \n",
        "  #Class attibute\n",
        "  in_path=''\n",
        "  dataset=''\n",
        "  files_list=''\n",
        "  out_path=''\n",
        "  workbook_path=''\n",
        "  workbook = ''\n",
        "  title_format=''\n",
        "  headers_format=''\n",
        "  cells_timesteps_format=''\n",
        "  cells_format=''\n",
        "\n",
        "  #Hard-coded parameters\n",
        "  timestamps=''\n",
        "  rois_labels=''\n",
        "  data_labels=''\n",
        "\n",
        "  n_bording_layers=0 #Number of bording layers\n",
        "\n",
        "  summary='' #The summary worksheet\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def __init__(self, in_path='', out_path='', n_bording_layers=0):\n",
        "    #Initializes headers\n",
        "    self.timestamps=['Before activation', 'Activation', '2 sec activation', 15, 30, 45, 60, 75, 90, 105, 120]\n",
        "    self.rois_labels=['Background', 'Activated Cell']\n",
        "    self.data_labels=['Raw data', 'Background subtracted', 'Normalized to 1', 'Normalized to 100%']\n",
        "\n",
        "\n",
        "    #Prepares path and names\n",
        "    self.in_path=in_path\n",
        "    tmp=in_path.split('/')\n",
        "    self.dataset=tmp[len(tmp)-2] # the path is supposed to end with /: last element of the table is therefore empty\n",
        "    self.out_path=out_path\n",
        "    self.n_bording_layers=n_bording_layers\n",
        "\n",
        "    #Prepares the labels\n",
        "    for i in range(1, n_bording_layers+1):\n",
        "      self.rois_labels.append('Border Cell '+str(i))\n",
        "      self.rois_labels.append('Border Cell '+str(i)+\"'\")\n",
        "\n",
        "    #Checks for previous XLSX output and removes it if it exists\n",
        "    self.workbook_path=self.out_path+self.dataset+'.xlsx'\n",
        "    if os.path.exists(self.workbook_path):\n",
        "      os.remove(self.workbook_path)\n",
        "\n",
        "    #Get the list of all files to analyze\n",
        "    self.files_list=[f.replace('.csv', '') for f in os.listdir(in_path) if (os.path.isfile(os.path.join(in_path, f)) and f.endswith('.csv'))]\n",
        "    self.files_list.sort()\n",
        "\n",
        "    #Creates the XLSX output\n",
        "    self.workbook = xlsxwriter.Workbook(self.workbook_path)\n",
        "\n",
        "    # Create a format to use for title\n",
        "    self.title_format = self.workbook.add_format({\n",
        "      'bold': 1,\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "  \n",
        "    # Create a format to use for headers\n",
        "    self.headers_format = self.workbook.add_format({\n",
        "      'bold': 1,\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "    \n",
        "    # Create a format to use for cells\n",
        "    self.cells_timesteps_format = self.workbook.add_format({\n",
        "      'bold': 1,\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "    \n",
        "    # Create a format to use for cells\n",
        "    self.cells_format = self.workbook.add_format({\n",
        "      'border': 1,\n",
        "      'align': 'center',\n",
        "      'valign': 'vcenter',\n",
        "      'text_wrap': 1,\n",
        "      'shrink': 1})\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def create_all_worksheets(self):\n",
        "    \"\"\"Creates and feeds all the spreadsheets based on the content of the input folder\"\"\"\n",
        "\n",
        "    print('******* Processing dataset '+self.dataset+' *******')\n",
        "    self.summary = self.workbook.add_worksheet('Summary')\n",
        "    print('Added Summary worksheet')\n",
        "    for f in self.files_list:\n",
        "      self.create_and_feed_single_worksheet(f)\n",
        "    self.feed_summary_worksheet()\n",
        "    self.workbook.close()\n",
        "\n",
        "    print('******* Done *******')\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def create_and_feed_single_worksheet(self, name):\n",
        "    \"\"\"Creates a single spreasheet from a single csv file\n",
        "\n",
        "    Keyword argument:\n",
        "    name -- name of the input csv file\"\"\"\n",
        "\n",
        "    worksheet = self.workbook.add_worksheet(name)\n",
        "    print('Added', name, 'worksheet')\n",
        "\n",
        "    #Reads data\n",
        "    input_csv=read_csv(self.in_path+name+\".csv\")\n",
        "    data=input_csv.get_data()\n",
        "\n",
        "    # Define offsets to put data and hard coded data\n",
        "    offset_row=4 #Depends on the number of lines for the headers\n",
        "    block_size=2*(2+self.n_bording_layers*2) #Headers' block size= (Bkgd+Activated+ 2*cells/layer)*2columns\n",
        "    \n",
        "    # --------Handles the raw data--------\n",
        "    #Adds general headers\n",
        "    worksheet.merge_range(0, 0, 0, block_size*len(self.data_labels), name, self.title_format)\n",
        "    worksheet.merge_range('A2:A4', 'Time', self.headers_format)\n",
        "\n",
        "    #Adds data header\n",
        "    index_data=0\n",
        "\n",
        "    for label in self.data_labels:\n",
        "      worksheet.merge_range(1, block_size*index_data+1, 1, block_size*index_data+block_size, label, self.headers_format)\n",
        "      \n",
        "      index_roi=0\n",
        "      for roi in self.rois_labels:\n",
        "        #Adds cell/data headers\n",
        "        worksheet.merge_range(2, 2*index_roi+1+block_size*index_data, 2, 2*index_roi+2+block_size*index_data, roi, self.headers_format)\n",
        "        worksheet.write(3, 2*index_roi+1+block_size*index_data, 'Area', self.headers_format)\n",
        "        worksheet.write(3, 2*index_roi+2+block_size*index_data, data['Area('+self.rois_labels[index_roi]+')'][0], self.headers_format)\n",
        "        index_roi=index_roi+1\n",
        "\n",
        "      index_data=index_data+1\n",
        "\n",
        "    \n",
        "    #Adds timestamp\n",
        "    index=0\n",
        "    for row in self.timestamps:\n",
        "      worksheet.write(index+offset_row, 0, row, self.cells_timesteps_format)\n",
        "      index=index+1\n",
        "\n",
        "    #Adds raw data\n",
        "    index_roi=0\n",
        "    nCol_per_dataType=2*len(self.rois_labels)\n",
        "    area_background='$C$4'  \n",
        "    for roi in self.rois_labels:\n",
        "      #Locate the area cells\n",
        "      area_curr_cell='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3, 2*index_roi+2))[0:2])\n",
        "\n",
        "      for row in range(len(data['RawIntDen('+self.rois_labels[index_roi]+')'])):\n",
        "        \n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1, row+offset_row, 2*index_roi+2, data['RawIntDen('+self.rois_labels[index_roi]+')'][row], self.cells_format)\n",
        "        \n",
        "        #Before activation subtracted\n",
        "        raw_background=xl_rowcol_to_cell(row+offset_row, 1)\n",
        "        raw_current_cell=xl_rowcol_to_cell(row+offset_row, 2*index_roi+1)\n",
        "\n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1+nCol_per_dataType, row+offset_row, 2*index_roi+2+nCol_per_dataType, '='+raw_current_cell+'-'+raw_background+'*'+area_curr_cell+'/'+area_background, self.cells_format)\n",
        "        \n",
        "        #Adds formulas for computations\n",
        "        #Normalized to 1 and %\n",
        "        sum_cells='+'.join([xl_rowcol_to_cell(row+offset_row, 2*cell+1+nCol_per_dataType) for cell in range(1, 2*self.n_bording_layers+2)])\n",
        "        \n",
        "        curr_cell=xl_rowcol_to_cell(row+offset_row, 2*index_roi+1+nCol_per_dataType)\n",
        "        formula='='+curr_cell+'/('+sum_cells+')'\n",
        "\n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1+2*nCol_per_dataType, row+offset_row, 2*index_roi+2+2*nCol_per_dataType, formula, self.cells_format)\n",
        "        worksheet.merge_range(row+offset_row, 2*index_roi+1+3*nCol_per_dataType, row+offset_row, 2*index_roi+2+3*nCol_per_dataType, formula.replace('=', '=100*'), self.cells_format)\n",
        "      index_roi=index_roi+1\n",
        "\n",
        "    #Formats the data\n",
        "    #Column width\n",
        "    worksheet.set_column(0, 0, 14.5)\n",
        "    worksheet.set_column(1, 1, 9)\n",
        "    worksheet.set_column(1, 2, 9)\n",
        "\n",
        "    #Adds graphs\n",
        "    #graph=self.workbook.add_chart({'type': 'scatter', 'subtype': 'smooth_with_markers'})\n",
        "    graph=self.workbook.add_chart({'type': 'line'})\n",
        "\n",
        "\n",
        "    # Configure the data series.\n",
        "    for roi in range(len(self.rois_labels)):\n",
        "      #Defines cells locations\n",
        "      n_lines=len(data['RawIntDen('+self.rois_labels[roi]+')'])-1+offset_row\n",
        "      col_data=2*roi+1+3*nCol_per_dataType\n",
        "\n",
        "      name_cell='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(2, col_data))[0:2])\n",
        "      categories_cell_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(offset_row+1, 0))[0:2])\n",
        "      categories_cell_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(n_lines, 0))[0:2])\n",
        "      values_cells_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(offset_row+1, col_data))[0:2])\n",
        "      values_cells_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(n_lines, col_data))[0:2])\n",
        "      \n",
        "      #Adds series to the graph\n",
        "      graph.add_series({\n",
        "          'name':       '='+name+'!'+name_cell,\n",
        "          'categories': '='+name+'!'+categories_cell_start+':'+categories_cell_end,\n",
        "          'values':     '='+name+'!'+values_cells_start+':'+values_cells_end,\n",
        "          #'data_labels': {'series_name': True},\n",
        "      })\n",
        "\n",
        "    #Graph formatting\n",
        "    graph.set_title({'name': name})\n",
        "    graph.set_x_axis({\n",
        "        'name' : 'Timepoint',\n",
        "        'text_axis': True,\n",
        "        'num_font':  {'rotation': -45},\n",
        "    })\n",
        "    graph.set_y_axis({\n",
        "        'name' : 'Normalized fluorescence (%)',\n",
        "    })\n",
        "    graph.set_size({\n",
        "        'width': 1024,\n",
        "        'height': 512,\n",
        "    })\n",
        "\n",
        "    #Inserts the graph\n",
        "    insert_graph_cell=xl_rowcol_to_cell(n_lines+2, 0)\n",
        "    worksheet.insert_chart(insert_graph_cell, graph)\n",
        "\n",
        "    #Inserts image\n",
        "    insert_img_cell=xl_rowcol_to_cell(n_lines+2, 16)\n",
        "    worksheet.insert_image(insert_img_cell, self.in_path+name+\".jpg\")\n",
        "\n",
        "  #-----------------------------------------------------------------------------  \n",
        "  #-----------------------------------------------------------------------------\n",
        "  def feed_summary_worksheet(self):\n",
        "    \"\"\"Feeds a summary spreasheet\"\"\"\n",
        "\n",
        "    n_rois=len(self.rois_labels) \n",
        "    n_files=len(self.files_list)\n",
        "    n_timepoints=len(self.timestamps)\n",
        "    n_value_types=len(self.data_labels)\n",
        "    n_col_per_data=2\n",
        "    offset_row=1;\n",
        "\n",
        "    #Adds headers\n",
        "    self.summary.merge_range(0, 0, 0, (n_files+3)*(n_rois-1), 'Data summary for '+self.dataset, self.title_format)\n",
        "    self.summary.merge_range('A2:A3', 'Time', self.headers_format)\n",
        "\n",
        "    index=1\n",
        "    for roi in range(1, n_rois): #Starts after background ROI\n",
        "      self.summary.merge_range(offset_row, (roi-1)*(n_files+3)+1, offset_row, roi*(n_files+3), self.rois_labels[roi], self.headers_format)\n",
        "      for dataset in self.files_list:\n",
        "        self.summary.write(offset_row+1, index, dataset, self.headers_format)\n",
        "        index=index+1\n",
        "      self.summary.write(offset_row+1, index, 'Mean', self.headers_format)\n",
        "      self.summary.write(offset_row+1, index+1, 'SD', self.headers_format)\n",
        "      self.summary.write(offset_row+1, index+2, 'n', self.headers_format)\n",
        "      index=index+3\n",
        "\n",
        "    #Adds timestamp\n",
        "    offset_row=offset_row+2\n",
        "\n",
        "    index=0\n",
        "    for row in self.timestamps:\n",
        "      self.summary.write(index+offset_row, 0, row, self.cells_timesteps_format)\n",
        "      index=index+1\n",
        "    \n",
        "    #Adds references to data and computes stats\n",
        "    for timepoint in range(0, n_timepoints):\n",
        "      index=1\n",
        "      for roi in range(1, n_rois): #Starts after background ROI\n",
        "        cell_to_ref=xl_rowcol_to_cell(offset_row+timepoint+1, 1+(n_col_per_data*n_rois)*(n_value_types-1)+2*roi)\n",
        "        data_cells=[]\n",
        "        for dataset in self.files_list:\n",
        "          self.summary.write(offset_row+timepoint, index, '='+dataset+'!'+cell_to_ref, self.cells_format)\n",
        "          data_cells.append(xl_rowcol_to_cell(offset_row+timepoint, index))\n",
        "          index=index+1\n",
        "        self.summary.write(offset_row+timepoint, index, '=AVERAGE('+data_cells[0]+':'+data_cells[len(data_cells)-1]+')', self.headers_format)\n",
        "        self.summary.write(offset_row+timepoint, index+1, '=STDEV('+data_cells[0]+':'+data_cells[len(data_cells)-1]+')', self.headers_format)\n",
        "        self.summary.write(offset_row+timepoint, index+2, '=COUNT('+data_cells[0]+':'+data_cells[len(data_cells)-1]+')', self.headers_format)\n",
        "        index=index+3\n",
        "\n",
        "    #Formats the data\n",
        "    #Column width\n",
        "    self.summary.set_column(0, 0, 14.5)\n",
        "    self.summary.set_column(1, 1, 9)\n",
        "    self.summary.set_column(1, 2, 9)\n",
        "\n",
        "    #Adds graphs\n",
        "    graph=self.workbook.add_chart({'type': 'line'})\n",
        "\n",
        "    n_lines=len(self.timestamps)-1\n",
        "    categories_cell_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+1, 0))[0:2])\n",
        "    categories_cell_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+n_lines, 0))[0:2])\n",
        "      \n",
        "    for roi in range(1, n_rois): #Starts after background ROI\n",
        "      #Defines cells locations\n",
        "      name_cell='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(1, 1+(n_files+3)*(roi-1)))[0:2])\n",
        "\n",
        "      values_cells_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+1, 1+(n_files+3)*(roi-1)+n_files))[0:2])\n",
        "      values_cells_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+n_lines, 1+(n_files+3)*(roi-1)+n_files))[0:2])\n",
        "\n",
        "      sd_cells_start='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+1, 1+(n_files+3)*(roi-1)+n_files+1))[0:2])\n",
        "      sd_cells_end='$'+'$'.join(re.split('(\\d+)', xl_rowcol_to_cell(3+n_lines, 1+(n_files+3)*(roi-1)+n_files+1))[0:2])\n",
        "\n",
        "      #Adds series to the graph\n",
        "      graph.add_series({\n",
        "          'name':       '=Summary!'+name_cell,\n",
        "          'categories': '=Summary!'+categories_cell_start+':'+categories_cell_end,\n",
        "          'values':     '=Summary!'+values_cells_start+':'+values_cells_end,\n",
        "          'y_error_bars': {\n",
        "            'type':         'custom',\n",
        "            'plus_values':  '=Summary!'+sd_cells_start+':'+sd_cells_end,\n",
        "            'minus_values': '=Summary!'+sd_cells_start+':'+sd_cells_end,\n",
        "          },\n",
        "          #'data_labels': {'series_name': True},\n",
        "      })\n",
        "\n",
        "    #Graph formatting\n",
        "    graph.set_title({'name': 'Data summary for '+self.dataset})\n",
        "    graph.set_x_axis({\n",
        "        'name' : 'Timepoint',\n",
        "        'text_axis': True,\n",
        "        'num_font':  {'rotation': -45},\n",
        "    })\n",
        "    graph.set_y_axis({\n",
        "        'name' : 'Normalized fluorescence (%)',\n",
        "    })\n",
        "    graph.set_size({\n",
        "        'width': 1024,\n",
        "        'height': 512,\n",
        "    })\n",
        "\n",
        "    #Inserts the graph\n",
        "    insert_graph_cell=xl_rowcol_to_cell(n_lines+5, 0)\n",
        "    self.summary.insert_chart(insert_graph_cell, graph)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ssPlEzldNfMq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 1.2.4: Defines how to upload the data, launch analysis and download the results, while keeping the swapping space clean_**"
      ],
      "metadata": {
        "id": "zNROf2gXQSjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown _Simply execute the following cell_\n",
        "\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "import shutil\n",
        "import os\n",
        "#-----------------UPLOAD DATA, PERFORM ANALYSIS AND DOWNLOAD THE RESULTS-----------------\n",
        "class compile_data():\n",
        "  \"\"\"\n",
        "  1-Uploads a zip file\n",
        "  2-Unzips it\n",
        "  3-Performs the analysis on all folders\n",
        "  4-Zips the results\n",
        "  5-Downloads the output zip file\n",
        "  \"\"\"\n",
        "\n",
        "  #Class attibute\n",
        "  uploaded=''\n",
        "  in_dir=''\n",
        "  in_file=''\n",
        "  out_file=''\n",
        "\n",
        "  def __init__(self):\n",
        "    '''Uploads the input zip file and keeps track of it as a class attribute'''\n",
        "    #File chooser\n",
        "    self.uploaded = files.upload()\n",
        "\n",
        "  def generate_output(self):\n",
        "    '''Unzips the uploaded file, performs analysis, creates the output zip file and downlaods it'''\n",
        "    #Unzip file(s), analyzes/downloads/clean up\n",
        "    for filename in self.uploaded.keys():\n",
        "      #Create a folder named after the file\n",
        "      zip_extract_path='/content/'+filename.replace('.zip', '')\n",
        "      os.mkdir(zip_extract_path)\n",
        "\n",
        "      #Extract the file\n",
        "      zip_in=ZipFile(filename, 'r')\n",
        "      zip_in.extractall(zip_extract_path)\n",
        "      zip_in.close()\n",
        "\n",
        "      #Analyze\n",
        "      self.in_file='/content/'+filename\n",
        "      self.in_dir=self.in_file.replace('.zip', '/')\n",
        "      self.out_file='/content/_dataAnalysed.zip'\n",
        "      params=read_param(self.in_dir+'params.txt')\n",
        "\n",
        "      out_dir=self.in_dir+'output/'\n",
        "      if not os.path.exists(out_dir):\n",
        "        os.mkdir(out_dir)\n",
        "\n",
        "      for dataset in params.paths:\n",
        "        in_path=self.in_dir+dataset\n",
        "        curr_xls=create_XLSX(in_path, out_dir, params.n_bording_layers)\n",
        "        curr_xls.create_all_worksheets()\n",
        "\n",
        "      zip_out = ZipFile(self.out_file, \"w\")\n",
        "      xlsx_files=[f for f in os.listdir(out_dir) if (os.path.isfile(os.path.join(out_dir, f)) and f.endswith('.xlsx'))]\n",
        "      \n",
        "      for f in xlsx_files:\n",
        "        zip_out.write(os.path.join(out_dir, f), f)\n",
        "      zip_out.close()\n",
        "\n",
        "      files.download(self.out_file)\n",
        "      self.clean_up_ze_mess()\n",
        "\n",
        "  def clean_up_ze_mess(self):\n",
        "    \"\"\"Removes the input zip file and the extracted folders\"\"\"\n",
        "    if(os.path.exists('/content/__MACOSX')):\n",
        "      shutil.rmtree('/content/__MACOSX')\n",
        "    shutil.rmtree(self.in_dir)\n",
        "    os.remove(self.in_file)\n",
        "\n",
        "  def delete_output_file(self):\n",
        "    '''Deletes the output zip file: DO NOT CALL IT BEFORE DOWNLOAD HAS ENDED'''\n",
        "    os.remove(self.out_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s1iZpq8eQWxK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Performs the analysis: upload data, analyze, download results\n"
      ],
      "metadata": {
        "id": "kowdervwOni-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 2.1: Upload data, analyze and download results_**\n",
        "_Processes the data_\n",
        "_Simply execute the following cell_"
      ],
      "metadata": {
        "id": "OuQpuLsqO6Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "where_the_magic_happens=compile_data()\n",
        "where_the_magic_happens.generate_output()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "9TtqNaWkiTd8",
        "outputId": "a4eb03df-b9e6-42c4-f5db-a4f741f5cf4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45a5982c-a25f-4fa7-9521-f82a85d72105\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-45a5982c-a25f-4fa7-9521-f82a85d72105\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving _dataToUpload.zip to _dataToUpload.zip\n",
            "******* Processing dataset dronpa DMSO 24h copie 2 *******\n",
            "Added Summary worksheet\n",
            "Added FRAP worksheet\n",
            "Added FRAP_001 worksheet\n",
            "Added FRAP_002 worksheet\n",
            "Added FRAP_003 worksheet\n",
            "Added FRAP_004 worksheet\n",
            "Added FRAP_005 worksheet\n",
            "Added FRAP_006 worksheet\n",
            "Added FRAP_007 worksheet\n",
            "******* Done *******\n",
            "******* Processing dataset dronpa DMSO 24h copie 3 *******\n",
            "Added Summary worksheet\n",
            "Added FRAP worksheet\n",
            "Added FRAP_001 worksheet\n",
            "Added FRAP_002 worksheet\n",
            "Added FRAP_003 worksheet\n",
            "Added FRAP_004 worksheet\n",
            "Added FRAP_005 worksheet\n",
            "Added FRAP_006 worksheet\n",
            "Added FRAP_007 worksheet\n",
            "******* Done *******\n",
            "******* Processing dataset dronpa DMSO 24h copie *******\n",
            "Added Summary worksheet\n",
            "Added FRAP worksheet\n",
            "Added FRAP_001 worksheet\n",
            "Added FRAP_002 worksheet\n",
            "Added FRAP_003 worksheet\n",
            "Added FRAP_004 worksheet\n",
            "Added FRAP_005 worksheet\n",
            "Added FRAP_006 worksheet\n",
            "Added FRAP_007 worksheet\n",
            "******* Done *******\n",
            "******* Processing dataset dronpa DMSO 24h *******\n",
            "Added Summary worksheet\n",
            "Added FRAP worksheet\n",
            "Added FRAP_001 worksheet\n",
            "Added FRAP_002 worksheet\n",
            "Added FRAP_003 worksheet\n",
            "Added FRAP_004 worksheet\n",
            "Added FRAP_005 worksheet\n",
            "Added FRAP_006 worksheet\n",
            "Added FRAP_007 worksheet\n",
            "******* Done *******\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40a6e04c-4054-4836-87c0-922937daedda\", \"_dataAnalysed.zip\", 1155252)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **_Step 2.2: Clean up temporary data_**\n",
        "_Cleans up the workspace: **to be executed once the results have been generated and downloaded**_"
      ],
      "metadata": {
        "id": "c-oPZYAWVIjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "where_the_magic_happens.delete_output_file()"
      ],
      "metadata": {
        "id": "Cmem3Ve_ibW-"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}